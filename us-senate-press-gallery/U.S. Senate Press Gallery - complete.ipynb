{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05412996",
   "metadata": {},
   "source": [
    "# U.S. Senate press gallery\n",
    "\n",
    "The goal: [Scrape the list of journalists accredited to cover the U.S. Senate](https://www.dailypress.senate.gov/membership/membership-lists/) into a CSV. A little spelunking in the source code will reveal a table ready for extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99adeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the list of headers for the CSV\n",
    "headers = [\n",
    "    'first',\n",
    "    'last',\n",
    "    'affiliation'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9744eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the request\n",
    "req = requests.get('https://www.dailypress.senate.gov/membership/membership-lists/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e710003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the HTML into soup\n",
    "soup = BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "# find the table\n",
    "table = soup.find('table')\n",
    "\n",
    "# grab a list of table rows (minus the header)\n",
    "rows = table.find_all('tr')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762a11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65af642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a CSV file to write data into\n",
    "with open('us-senate-press-gallery.csv', 'w', newline='') as outfile:\n",
    "\n",
    "    # create a writer object\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # write the list of headers to file\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    # loop over the rows\n",
    "    for row in rows:\n",
    "\n",
    "        # find the cells in this row\n",
    "        cells = row.find_all('td')\n",
    "        \n",
    "        # extract each piece of data from the list\n",
    "        \n",
    "        # first name is the first ([0]) list item\n",
    "        first_name = cells[0].text.strip()\n",
    "        \n",
    "        # last name is second ([1])\n",
    "        last_name = cells[1].text.strip()\n",
    "\n",
    "        # affiliation is third ([2])\n",
    "        affiliation = cells[2].text.strip()\n",
    "\n",
    "        # write row to file\n",
    "        writer.writerow([first_name, last_name, affiliation])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
